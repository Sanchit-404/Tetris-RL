{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3709db1a-ba7b-4b52-9810-4c16487a12dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-30 00:21:52.870086: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-30 00:21:52.913037: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-30 00:21:53.558343: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-30 00:21:54.486638: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "  0%|                                                                                          | 0/3000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from dqn_agent import DQNAgent\n",
    "from tetris import Tetris\n",
    "from datetime import datetime\n",
    "from statistics import mean\n",
    "from logs import CustomTensorBoard\n",
    "from tqdm import tqdm\n",
    "        \n",
    "\n",
    "# Run dqn with Tetris\n",
    "def dqn():\n",
    "    env = Tetris()\n",
    "    episodes = 3000 # total number of episodes\n",
    "    max_steps = None # max number of steps per game (None for infinite)\n",
    "    epsilon_stop_episode = 2000 # at what episode the random exploration stops\n",
    "    mem_size = 1000 # maximum number of steps stored by the agent\n",
    "    discount = 0.95 # discount in the Q-learning formula (see DQNAgent)\n",
    "    batch_size = 128 # number of actions to consider in each training\n",
    "    epochs = 1 # number of epochs per training\n",
    "    render_every = 50 # renders the gameplay every x episodes\n",
    "    render_delay = None # delay added to render each frame (None for no delay)\n",
    "    log_every = 50 # logs the current stats every x episodes\n",
    "    replay_start_size = 1000 # minimum steps stored in the agent required to start training\n",
    "    train_every = 1 # train every x episodes\n",
    "    n_neurons = [32, 32, 32] # number of neurons for each activation layer\n",
    "    activations = ['relu', 'relu', 'relu', 'linear'] # activation layers\n",
    "    save_best_model = True # saves the best model so far at \"best.keras\"\n",
    "\n",
    "    agent = DQNAgent(env.get_state_size(),\n",
    "                     n_neurons=n_neurons, activations=activations,\n",
    "                     epsilon_stop_episode=epsilon_stop_episode, mem_size=mem_size,\n",
    "                     discount=discount, replay_start_size=replay_start_size)\n",
    "\n",
    "    log_dir = f'logs/tetris-nn={str(n_neurons)}-mem={mem_size}-bs={batch_size}-e={epochs}-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "    log = CustomTensorBoard(log_dir=log_dir)\n",
    "\n",
    "    scores = []\n",
    "    best_score = 0\n",
    "\n",
    "    for episode in tqdm(range(episodes)):\n",
    "        current_state = env.reset()\n",
    "        done = False\n",
    "        steps = 0\n",
    "\n",
    "        if render_every and episode % render_every == 0:\n",
    "            render = True\n",
    "        else:\n",
    "            render = False\n",
    "\n",
    "        # Game\n",
    "        while not done and (not max_steps or steps < max_steps):\n",
    "            # state -> action\n",
    "            next_states = {tuple(v):k for k, v in env.get_next_states().items()}\n",
    "            best_state = agent.best_state(next_states.keys())\n",
    "            best_action = next_states[best_state]\n",
    "\n",
    "            reward, done = env.play(best_action[0], best_action[1], render=render,\n",
    "                                    render_delay=render_delay)\n",
    "            \n",
    "            agent.add_to_memory(current_state, best_state, reward, done)\n",
    "            current_state = best_state\n",
    "            steps += 1\n",
    "\n",
    "        scores.append(env.get_game_score())\n",
    "\n",
    "        # Train\n",
    "        if episode % train_every == 0:\n",
    "            agent.train(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "        # Logs\n",
    "        if log_every and episode and episode % log_every == 0:\n",
    "            avg_score = mean(scores[-log_every:])\n",
    "            min_score = min(scores[-log_every:])\n",
    "            max_score = max(scores[-log_every:])\n",
    "\n",
    "            log.log(episode, avg_score=avg_score, min_score=min_score,\n",
    "                    max_score=max_score)\n",
    "\n",
    "        # Save model\n",
    "        if save_best_model and env.get_game_score() > best_score:\n",
    "            print(f'Saving a new best model (score={env.get_game_score()}, episode={episode})')\n",
    "            best_score = env.get_game_score()\n",
    "            agent.save_model(\"best.keras\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dqn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f050d7-67f8-4b8c-a631-d93a056d1a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-30 00:22:51.002032: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-30 00:22:51.041751: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-30 00:22:51.657807: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-30 00:22:52.610646: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "  0%|                                                  | 0/3000 [00:00<?, ?it/s]qt.qpa.xcb: could not connect to display \n",
      "qt.qpa.plugin: Could not load the Qt platform plugin \"xcb\" in \"/home/grads/sanchit23/.local/lib/python3.8/site-packages/cv2/qt/plugins\" even though it was found.\n",
      "This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n",
      "\n",
      "Available platform plugins are: xcb.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 run.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97affb51-bdaa-45c2-941e-302dbd4ed401",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
